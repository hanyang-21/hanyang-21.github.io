<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Hanyang Wang</title>

    <meta name="author" content="Hanyang Wang">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Hanyang Wang | 汪晗阳
                </p>
                <p>
                  I'm currently an undergraduate student in the Department of <a href="https://www.cs.tsinghua.edu.cn/csen/">Computer Science and Technology</a> at <a href="https://www.tsinghua.edu.cn/en/">Tsinghua University</a>. 
                  I'm also serving as an intern working closly with Prof. <a href="https://duanyueqi.github.io/">Yueqi Duan</a> and <a href="https://liuff19.github.io/">Fangfu Liu</a>. 
                </p>
                <p>
                  My research interests lie in <b>3D Computer Vision</b> and <b>AIGC</b>.
                </p>

                <p style="text-align:center">
                  <a href="mailto:hanyang-21@mails.tsinghua.edu.cn">Email</a> &nbsp;/&nbsp;
                  <a href="https://hanyang-21.github.io/">CV</a> &nbsp;/&nbsp;
                  <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp;/&nbsp; -->
                  <a href="https://scholar.google.com/citations?user=ex8jWtUAAAAJ">Scholar</a> &nbsp;/&nbsp;
                  <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp;/&nbsp; -->
                  <a href="https://github.com/hanyang-21">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/hanyang.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/hanyang.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  <p>
                    * indicates equal contribution. Some papers are <span class="highlight">highlighted</span>.
                  </p>
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr onmouseout="cat3d_stop()" onmouseover="cat3d_start()" bgcolor="#ffffd0">
              <td style="padding:20px;width:30%;max-width:30%" align="center">
                <img style="width:100%;max-width:100%" src='images/VideoScene.png' alt="dise">
              </td>
              <td style="width:75%;vertical-align:middle" valign="center">
                <papertitle>VideoScene: Distilling Video Diffusion Model to Generate 3D Scenes in One Step</papertitle>
                <br>
                <strong>Hanyang Wang*</strong>,
                <a href="https://liuff19.github.io/">Fangfu Liu</a>*, 
                Jiawei Chi,
                <a href="https://duanyueqi.github.io/"> Yueqi Duan </a>

                <br>
                <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2025
                <br>
                <font color="red"><strong>Highlight</strong></font>
                <br>
                <a href="https://arxiv.org/abs/2504.01956">[arXiv]</a>
                <a href="https://github.com/hanyang-21/VideoScene">[Code]</a>
                <a href="https://https://hanyang-21.github.io/VideoScene/">[Project Page]</a> 
                <br>
                <p>
                  In this paper, we propose VideoScene to distill the video diffusion model to generate 3D scenes in one step, aiming to build an efficient and effective tool to bridge the gap from video to 3D.
                </p>
              </td>
            </tr>


            <tr>
              <td style="padding:20px;width:30%;max-width:30%" align="center">
                <img style="width:100%;max-width:100%" src="images/Video-T1.png" alt="dise">
              </td>
              <td width="75%" valign="center">
                <papertitle>Video-T1: Test-Time Scaling for Video Generation</papertitle>
                <br>
                <a href="https://liuff19.github.io/">Fangfu Liu*</a>,
                <strong> Hanyang Wang* </strong>,
                Yimo Cai,
                <a href="https://iseesaw.github.io/"> Kaiyan Zhang </a>,
                <a href="https://xiaohangzhan.github.io/"> Xiaohang Zhan </a>,
                <a href="https://duanyueqi.github.io/"> Yueqi Duan </a>
                <br>
                <em>Arxiv, 2025</em>
                <br>
                <a href="https://arxiv.org/abs/2503.18942">[arXiv]</a>
                <a href="https://github.com/liuff19/Video-T1">[Code]</a>
                <a href="https://liuff19.github.io/Video-T1/">[Project Page]</a> 
                <br>
                <p> We present the generative effects and performance improvements of video generation under test-time scaling (TTS) settings. The videos generated with TTS are of higher quality and more consistent with the prompt than those generated without TTS.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:30%;max-width:30%;vertical-align:middle">
                <img style="width:100%;max-width:100%" src="images/ReconX.png" alt="dise">
              </td>
              <td width="75%" valign="center">
                <papertitle>ReconX: Reconstruct Any Scene from Sparse Views with Video Diffusion Model</papertitle>
                <br>
                <a href="https://liuff19.github.io/">Fangfu Liu*</a>,
                <a href="https://github.com/wenqsun"> Wenqiang Sun* </a>,
                <strong> Hanyang Wang* </strong>,
                <a href="https://yikaiw.github.io/"> Yikai Wang </a>,
                <a href="https://github.com/sunboy0617"> Haowen Sun </a>,
                <a href="https://jamesyjl.github.io/"> Junliang Ye </a>,
                <br>
                <a href="https://eejzhang.people.ust.hk/home.html"> Jun Zhang </a>,
                <a href="https://duanyueqi.github.io/"> Yueqi Duan </a>
                <br>
                <em>Arxiv, 2024</em>
                <br>
                <a href="https://arxiv.org/abs/2408.16767">[arXiv]</a>
                <a href="https://github.com/liuff19/ReconX">[Code]</a>
                <a href="https://liuff19.github.io/ReconX/">[Project Page]</a> 
                <br>
                <p> In this paper, we propose ReconX, a novel 3D scene reconstruction paradigm that reframes the ambiguous reconstruction challenge as a temporal generation task. The key insight is to unleash the strong generative prior of large pre-trained video diffusion models for sparse-view reconstruction. </p>
              </td>
            </tr>
            
            <tr>
              <td style="padding:20px;width:30%;max-width:30%;vertical-align:middle">
                <img style="width:100%;max-width:100%" src="images/Physics3D.png" alt="dise">
              </td>
              <td width="75%" valign="center">
                <papertitle>Physics3D: Learning Physical Properties of 3D Gaussians via Video Diffusion</papertitle>
                <br>
                Fangfu Liu*, 
                <strong>Hanyang Wang*</strong>
                <a href="https://scholar.google.com/citations?user=i4kyLbwAAAAJ"> Shunyu Yao </a>,
                Shengjun Zhang,
                <a href="https://scholar.google.com/citations?user=6a79aPwAAAAJ"> Jie Zhou</a>,
                <a href="https://duanyueqi.github.io/"> Yueqi Duan </a>
                <br>
                <em>Arxiv, 2024</em>
                <br>
                <a href="https://arxiv.org/abs/2406.04338">[arXiv]</a>
                <a href="https://github.com/liuff19/Physics3D">[Code]</a>
                <a href="https://liuff19.github.io/Physics3D">[Project Page]</a> 
                <br>
                <p> In this paper, we propose Physics3D, a novel method for learning various physical properties of 3D objects through a video diffusion model. Our approach involves designing a highly generalizable physical simulation system based on a viscoelastic material model, which enables us to simulate a wide range of materials with high-fidelity capabilities. </p>
              </td>
            </tr>
  
  
            <tr>
              <td style="padding:20px;width:30%;max-width:30%;vertical-align:middle">
                <img style="width:100%;max-width:100%" src="images/Unique3D.jpg" alt="dise">
              </td>
              <td width="75%" valign="center">
                <papertitle>Unique3D: High-Quality and Efficient 3D Mesh Generation from a Single Image</papertitle>
                <br>
                <a href="https://scholar.google.com/citations?user=VTU0gysAAAAJ&hl=zh-CN&oi=ao"> Kailu Wu </a>, 
                Fangfu Liu, 
                Zhihan Cai, 
                Runjie Yan, 
                <strong>Hanyang Wang</strong>, 
                Yating Hu,
                <br>
                <a href="https://duanyueqi.github.io/"> Yueqi Duan </a>,
                <a href="https://group.iiis.tsinghua.edu.cn/~maks/"> Kaisheng Ma </a>
                <br>
                <em>Conference on Neural Information Processing Systems (<strong>NeurIPS</strong>)</em>, 2024
                <br>
                <a href="https://arxiv.org/abs/2405.20343">[arXiv]</a>
                <a href="https://github.com/AiuniAI/Unique3D">[Code]</a>
                <a href="https://wukailu.github.io/Unique3D/">[Project Page]</a> 
                <br>
                <p> In this work, we introduce Unique3D, a novel image-to-3D framework for efficiently generating high-quality 3D meshes from single-view images, featuring state-of-the-art generation fidelity and strong generalizability. Unique3D can generate a high-fidelity textured mesh from a single orthogonal RGB image of any object in under 30 seconds.  </p>
              </td>
            </tr>


            <tr>
              <td style="padding:20px;width:30%;max-width:30%;vertical-align:middle">
                <img style="width:100%;max-width:100%" src="images/make-your-3d.png" alt="dise">
              </td>
              <td width="75%" valign="center">
                <papertitle>Make-Your-3D: Fast and Consistent Subject-Driven 3D Content Generation</papertitle>
                <br>
                Fangfu Liu, 
                <strong>Hanyang Wang</strong>, 
                Weiliang Chen,
                Haowen Sun,
                <a href="https://duanyueqi.github.io/"> Yueqi Duan </a>
                <br>
                <em>European Conference on Computer Vision (<strong>ECCV</strong>)</em>, 2024
                <br>
                <a href="https://arxiv.org/abs/2403.09625">[arXiv]</a>
                <a href="https://github.com/liuff19/Make-Your-3D">[Code]</a>
                <a href="https://liuff19.github.io/Make-Your-3D/">[Project Page]</a> 
                <br>
                <p> We introduce a novel 3D customization method, dubbed Make-Your-3D that can personalize high-fidelity and consistent 3D content from only a single image of a subject with text description within 5 
                    minutes. </p>
              </td>
            </tr>

          </tbody></table>

          <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody><tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Honors and Awards</heading>
              <p>
                <li style="margin: 5px;"> <b>Scholarship</b></li>
              </p>
            </td>
          </tr></tbody></table> -->
  
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <a href="https://jonbarron.info/">Website Template</a>
              </p>
            </td>
          </tr>
        </tbody></table>
          
        </td>
      </tr>
    </table>
  </body>
</html>
